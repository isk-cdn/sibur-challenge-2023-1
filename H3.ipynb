{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1badbc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import albumentations as alb\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "604937ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод для считывания ролика в массив, (from baseline)\n",
    "\n",
    "def read_clip(f_name: str, start: int = 0, transposed: bool = False):\n",
    "    \"\"\"Прочесть ролик в массив.\"\"\"\n",
    "\n",
    "    cpr = cv2.VideoCapture(f_name)\n",
    "    has_frame = True\n",
    "    frames = []\n",
    "\n",
    "    while has_frame:\n",
    "        has_frame, frame = cpr.read()\n",
    "        if has_frame:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            if transposed:\n",
    "                frame = np.moveaxis(frame, -1, 0).copy()\n",
    "\n",
    "            frames.append(frame)\n",
    "    cpr.release()\n",
    "    return np.array(frames)[start:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f74087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Жесткое разделение данных для обучения и валидации\n",
    "\n",
    "base_dir = 'ds/train/'\n",
    "os.mkdir('ds/val')\n",
    "\n",
    "split = 0.3\n",
    "for class_name in os.listdir(base_dir):\n",
    "\n",
    "    target_dir = f\"ds/val/{class_name}/\"\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "\n",
    "    class_clips = [\n",
    "        clip_file for clip_file in\n",
    "        os.listdir(base_dir + class_name)\n",
    "        if clip_file.endswith('.mp4')\n",
    "    ]\n",
    "    split_value = int(len(class_clips) * split)\n",
    "    for i, clip_file in enumerate(class_clips):\n",
    "        if i < split_value:\n",
    "            os.rename(\n",
    "                f\"{base_dir}{class_name}/{clip_file}\",\n",
    "                f\"{target_dir}{clip_file}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f38cdde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирование и считывание наборов данных\n",
    "\n",
    "classes_dict = {\n",
    "    'no_action': 0,\n",
    "    'train_in_out': 1,\n",
    "    'bridge_up': 2,\n",
    "    'bridge_down': 3,\n",
    "}\n",
    "\n",
    "_x_train, _x_val = [], []\n",
    "_y_train, _y_val = [], []\n",
    "\n",
    "ds_root = 'ds/'\n",
    "for ds_part in ('train', 'val'):\n",
    "\n",
    "    x_set, y_set = (_x_train, _y_train) if ds_part == 'train' else (_x_val, _y_val)\n",
    "\n",
    "    for class_name in os.listdir(f\"{ds_root}{ds_part}\"):\n",
    "        class_clips_files = [\n",
    "            clip_file for clip_file in\n",
    "            os.listdir(f\"{ds_root}{ds_part}/{class_name}\")\n",
    "            if clip_file.endswith('.mp4')\n",
    "        ]\n",
    "\n",
    "        x_set += [\n",
    "            read_clip(f\"{ds_root}{ds_part}/{class_name}/{clip_file}\")\n",
    "            for clip_file in class_clips_files\n",
    "        ]\n",
    "        y_set += [classes_dict[class_name]] * len(class_clips_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2919964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аугментации. \n",
    "\n",
    "train_transforms = alb.Compose(transforms=[\n",
    "    alb.HorizontalFlip(p=0.5),\n",
    "    alb.ShiftScaleRotate(rotate_limit=15, scale_limit=0.1, shift_limit=0, p=0.5),\n",
    "    alb.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),\n",
    "    alb.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
    "    alb.HueSaturationValue(hue_shift_limit=15, sat_shift_limit=15, val_shift_limit=15, p=0.5),\n",
    "],\n",
    "    additional_targets={f'image{i}': 'image' for i in range(1, 300)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90ffbbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предобработка Х в батче:\n",
    "# Случайная подрезка ролика до 300 кадров + вырезание куска в 50 кадров в случайном месте + аугментации\n",
    "# Затем ролик превращается в изображение со средними значениями от всех кадров\n",
    "\n",
    "def prepare_batch_x(data, train=True):\n",
    "    x = []\n",
    "    for clip in data:\n",
    "\n",
    "        if len(clip) > 300:\n",
    "            split_idx = random.randint(0, len(clip) - 300)\n",
    "            clip = clip[split_idx: split_idx + 300]\n",
    "\n",
    "        mask_start = random.randint(0, len(clip))\n",
    "        clip = np.concatenate([clip[:mask_start], clip[mask_start + 50:]], 0)\n",
    "\n",
    "        if train:\n",
    "            images = {f'image{frame_number}': frame for frame_number, frame in enumerate(clip[1:], start=1)}\n",
    "            images['image'] = clip[0]\n",
    "            clip = train_transforms(**images)\n",
    "            clip.pop('image', None)\n",
    "            clip = np.array(list(clip.values()))\n",
    "\n",
    "        clip_image = np.sum(clip, 0) // len(clip)\n",
    "\n",
    "        clip_image = np.transpose(clip_image, [-1, 0, 1])\n",
    "\n",
    "        x.append(clip_image / 255.)\n",
    "\n",
    "    return np.array(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c54d0ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод для итерирования батчей\n",
    "\n",
    "def iterate_batches(x, y, batch_size, dev, train=True):\n",
    "    indices = np.random.permutation(np.arange(len(x)))\n",
    "    for start in range(0, len(indices), batch_size):\n",
    "        ix = indices[start: start + batch_size]\n",
    "        x_i = prepare_batch_x([x[ii] for ii in ix], train=train)\n",
    "        x_i = torch.as_tensor(x_i, dtype=torch.float32).to(dev)\n",
    "        y_i = torch.as_tensor([y[ii] for ii in ix], dtype=torch.int64).to(dev)\n",
    "        yield x_i, y_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0d6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Трейнер\n",
    "\n",
    "def train_loop(\n",
    "        model, opt, dev,\n",
    "        x_train, y_train,\n",
    "        x_val=None, y_val=None,\n",
    "        num_epochs=15, batch_size=50\n",
    "):\n",
    "    train_loss = []\n",
    "    val_accuracy = []\n",
    "\n",
    "    for _epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.train(True)\n",
    "\n",
    "        for x_batch, y_batch in iterate_batches(x_train, y_train, batch_size, dev):\n",
    "            loss = F.cross_entropy(model(x_batch), y_batch).mean()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            train_loss.append(loss.data.cpu())\n",
    "\n",
    "        if x_val and y_val:\n",
    "            model.train(False)\n",
    "            for x_batch, y_batch in iterate_batches(x_val, y_val, batch_size, dev, train=False):\n",
    "                logits = model(x_batch).max(1)[1].data\n",
    "                val_accuracy.append((y_batch == logits).cpu().numpy().mean())\n",
    "\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            _epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"    training loss (in-iteration): \\t{:.6f}\".format(\n",
    "            np.mean(train_loss[-len(x_train) // batch_size:])))\n",
    "        if x_val and y_val:\n",
    "            print(\"    validation accuracy: \\t\\t\\t{:.4f} %\".format(\n",
    "                np.mean(val_accuracy[-len(x_val) // batch_size:]) * 100))\n",
    "\n",
    "    model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce3d3d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание и подготовка модели\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_h1 = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
    "model_h1.classifier[1] = nn.Linear(in_features=1280, out_features=4)\n",
    "\n",
    "for i, param in enumerate(model_h1.children()):\n",
    "    if i < 2:\n",
    "        param.requires_grad = False\n",
    "\n",
    "model_h1.to(device)\n",
    "optimizer = torch.optim.Adam(model_h1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43296f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10 took 111.247s\n",
      "    training loss (in-iteration): \t0.579955\n",
      "    validation accuracy: \t\t\t78.8194 %\n",
      "Epoch 2 of 10 took 102.611s\n",
      "    training loss (in-iteration): \t0.099521\n",
      "    validation accuracy: \t\t\t95.7639 %\n",
      "Epoch 3 of 10 took 103.676s\n",
      "    training loss (in-iteration): \t0.179242\n",
      "    validation accuracy: \t\t\t96.2500 %\n",
      "Epoch 4 of 10 took 104.443s\n",
      "    training loss (in-iteration): \t0.156894\n",
      "    validation accuracy: \t\t\t97.0139 %\n",
      "Epoch 5 of 10 took 103.591s\n",
      "    training loss (in-iteration): \t0.124425\n",
      "    validation accuracy: \t\t\t89.5139 %\n",
      "Epoch 6 of 10 took 104.985s\n",
      "    training loss (in-iteration): \t0.083474\n",
      "    validation accuracy: \t\t\t94.0278 %\n",
      "Epoch 7 of 10 took 98.795s\n",
      "    training loss (in-iteration): \t0.040349\n",
      "    validation accuracy: \t\t\t98.7500 %\n",
      "Epoch 8 of 10 took 104.933s\n",
      "    training loss (in-iteration): \t0.017985\n",
      "    validation accuracy: \t\t\t98.2639 %\n",
      "Epoch 9 of 10 took 102.288s\n",
      "    training loss (in-iteration): \t0.087043\n",
      "    validation accuracy: \t\t\t100.0000 %\n",
      "Epoch 10 of 10 took 102.141s\n",
      "    training loss (in-iteration): \t0.092922\n",
      "    validation accuracy: \t\t\t99.3750 %\n"
     ]
    }
   ],
   "source": [
    "# Трансферное обучение модели\n",
    "\n",
    "train_loop(\n",
    "    model_h1, optimizer, device,\n",
    "    _x_train, _y_train, _x_val, _y_val,\n",
    "    num_epochs=10, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e90faf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'h3'\n",
    "epoch = 10\n",
    "torch.save(model_h1, f'models/classifier-{model_name}-{epoch}.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91e2dbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10 took 103.513s\n",
      "    training loss (in-iteration): \t0.091735\n",
      "    validation accuracy: \t\t\t100.0000 %\n",
      "Epoch 2 of 10 took 101.393s\n",
      "    training loss (in-iteration): \t0.038647\n",
      "    validation accuracy: \t\t\t100.0000 %\n",
      "Epoch 3 of 10 took 102.170s\n",
      "    training loss (in-iteration): \t0.045316\n",
      "    validation accuracy: \t\t\t100.0000 %\n",
      "Epoch 4 of 10 took 95.304s\n",
      "    training loss (in-iteration): \t0.015004\n",
      "    validation accuracy: \t\t\t99.3750 %\n",
      "Epoch 5 of 10 took 108.631s\n",
      "    training loss (in-iteration): \t0.041417\n",
      "    validation accuracy: \t\t\t99.3750 %\n",
      "Epoch 6 of 10 took 100.798s\n",
      "    training loss (in-iteration): \t0.006608\n",
      "    validation accuracy: \t\t\t99.3750 %\n",
      "Epoch 7 of 10 took 105.109s\n",
      "    training loss (in-iteration): \t0.036377\n",
      "    validation accuracy: \t\t\t99.3750 %\n",
      "Epoch 8 of 10 took 101.181s\n",
      "    training loss (in-iteration): \t0.032112\n",
      "    validation accuracy: \t\t\t98.7500 %\n",
      "Epoch 9 of 10 took 101.680s\n",
      "    training loss (in-iteration): \t0.024183\n",
      "    validation accuracy: \t\t\t99.3750 %\n",
      "Epoch 10 of 10 took 103.555s\n",
      "    training loss (in-iteration): \t0.048654\n",
      "    validation accuracy: \t\t\t100.0000 %\n"
     ]
    }
   ],
   "source": [
    "# Продолжение обучения модели, теперь обучаются все слои, но с уменьшенным lr оптимизатора\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_h1 = torch.load('models/classifier-h3-10.ckpt')\n",
    "for i, param in enumerate(model_h1.children()):\n",
    "    param.requires_grad = True\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model_h1.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_h1.parameters(), lr=0.0004)\n",
    "train_loop(\n",
    "    model_h1, optimizer, device,\n",
    "    _x_train, _y_train, _x_val, _y_val,\n",
    "    num_epochs=10, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c78fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'h3'\n",
    "epoch = 20\n",
    "torch.save(model_h1, f'models/classifier-{model_name}-{epoch}.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "687c338d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10 took 240.409s\n",
      "    training loss (in-iteration): \t0.349335\n",
      "Epoch 2 of 10 took 241.111s\n",
      "    training loss (in-iteration): \t0.239774\n",
      "Epoch 3 of 10 took 242.701s\n",
      "    training loss (in-iteration): \t0.126809\n",
      "Epoch 4 of 10 took 244.129s\n",
      "    training loss (in-iteration): \t0.121535\n",
      "Epoch 5 of 10 took 244.349s\n",
      "    training loss (in-iteration): \t0.110417\n",
      "Epoch 6 of 10 took 234.874s\n",
      "    training loss (in-iteration): \t0.085850\n",
      "Epoch 7 of 10 took 241.122s\n",
      "    training loss (in-iteration): \t0.094086\n",
      "Epoch 8 of 10 took 236.140s\n",
      "    training loss (in-iteration): \t0.031532\n",
      "Epoch 9 of 10 took 239.824s\n",
      "    training loss (in-iteration): \t0.055752\n",
      "Epoch 10 of 10 took 238.216s\n",
      "    training loss (in-iteration): \t0.050000\n"
     ]
    }
   ],
   "source": [
    "# Продолжение обучения модели, теперь на обучение отправляются все данные и усиливается аугментация \n",
    "\n",
    "train_transforms = alb.Compose(transforms=[\n",
    "    alb.HorizontalFlip(p=0.5),\n",
    "    alb.ShiftScaleRotate(rotate_limit=45, scale_limit=0.2, shift_limit=0, p=0.7),\n",
    "    alb.RGBShift(r_shift_limit=35, g_shift_limit=35, b_shift_limit=35, p=0.7),\n",
    "    alb.RandomBrightnessContrast(brightness_limit=0.35, contrast_limit=0.35, p=0.7),\n",
    "    alb.HueSaturationValue(hue_shift_limit=35, sat_shift_limit=35, val_shift_limit=35, p=0.7),\n",
    "    alb.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.7, p=0.3),\n",
    "],\n",
    "    additional_targets={f'image{i}': 'image' for i in range(1, 300)}\n",
    ")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_h1 = torch.load('models/classifier-h3-20.ckpt')\n",
    "for i, param in enumerate(model_h1.children()):\n",
    "    param.requires_grad = True\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "model_h1.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_h1.parameters(), lr=0.0004)\n",
    "train_loop(\n",
    "    model_h1, optimizer, device,\n",
    "    _x_train + _x_val, _y_train + _y_val,\n",
    "    num_epochs=10, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fdacdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'h3'\n",
    "epoch = 30\n",
    "torch.save(model_h1, f'models/classifier-{model_name}-{epoch}.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2acb191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
